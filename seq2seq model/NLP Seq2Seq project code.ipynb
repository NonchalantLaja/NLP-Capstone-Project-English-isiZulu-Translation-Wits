{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compatible-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cathedral-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_zu_train = pd.read_csv('en-zu.training.csv')\n",
    "zu_en_train = pd.read_csv('zu-en.training.csv')\n",
    "\n",
    "en_zu_eval = pd.read_csv('en-zu.eval.csv')\n",
    "zu_en_eval = pd.read_csv('zu-en.eval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-afghanistan",
   "metadata": {},
   "source": [
    "Since translating from English to Zulu, Use en-zu data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "isolated-metabolism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zu</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>His solo albums in the 60s were some of the mo...</td>\n",
       "      <td>Ama-albhamu akhe e-solo eminyaka yawo-60 angam...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From which it follows that if you want to save...</td>\n",
       "      <td>Ukusuka lapho kuzobe sekulandela ukuthi uma uf...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thirty years after St. John Paul II begged Moz...</td>\n",
       "      <td>Ngemuva kweminyaka engamashumi amathathu u-St....</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wynford yw sylfaenydd Stafell Fyw yng Nghaerdy...</td>\n",
       "      <td>Wynford yw sylfaenydd Stafell Fyw yng Nghaerdy...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unai Emery's side have won just two of their l...</td>\n",
       "      <td>Iqembu lika-Unai Emery lisanqobe imidlalo emib...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  His solo albums in the 60s were some of the mo...   \n",
       "1  From which it follows that if you want to save...   \n",
       "2  Thirty years after St. John Paul II begged Moz...   \n",
       "3  Wynford yw sylfaenydd Stafell Fyw yng Nghaerdy...   \n",
       "4  Unai Emery's side have won just two of their l...   \n",
       "\n",
       "                                                  zu           source  \n",
       "0  Ama-albhamu akhe e-solo eminyaka yawo-60 angam...  News Crawl 2019  \n",
       "1  Ukusuka lapho kuzobe sekulandela ukuthi uma uf...  News Crawl 2019  \n",
       "2  Ngemuva kweminyaka engamashumi amathathu u-St....  News Crawl 2019  \n",
       "3  Wynford yw sylfaenydd Stafell Fyw yng Nghaerdy...  News Crawl 2019  \n",
       "4  Iqembu lika-Unai Emery lisanqobe imidlalo emib...  News Crawl 2019  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_zu_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nominated-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lomkhakha kufanele uthuthukiswe,� lawa amazwi ...</td>\n",
       "      <td>This sector needs to be developed, � These are...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...</td>\n",
       "      <td>All questions: Phone: 031- 311 3154 (Shaks Ram...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Axhumanisa umphakathi noMkhandlu ngoba abika k...</td>\n",
       "      <td>They connect the community with the Council be...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Umsebenzi kaSolwazi uveze ukubaluleka nokuba i...</td>\n",
       "      <td>The Professor's work has highlighted the impor...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sibusiso Sithole IMenenja yeDolobha IsImEmo sE...</td>\n",
       "      <td>Sibusiso Sithole, City Manager - Invitation To...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Lomkhakha kufanele uthuthukiswe,� lawa amazwi ...   \n",
       "1  Yonke imibuzo: Ucingo: 031- 311 3154 (Shaks Ra...   \n",
       "2  Axhumanisa umphakathi noMkhandlu ngoba abika k...   \n",
       "3  Umsebenzi kaSolwazi uveze ukubaluleka nokuba i...   \n",
       "4  Sibusiso Sithole IMenenja yeDolobha IsImEmo sE...   \n",
       "\n",
       "                                                  en     source  \n",
       "0  This sector needs to be developed, � These are...  Newspaper  \n",
       "1  All questions: Phone: 031- 311 3154 (Shaks Ram...  Newspaper  \n",
       "2  They connect the community with the Council be...  Newspaper  \n",
       "3  The Professor's work has highlighted the impor...  Newspaper  \n",
       "4  Sibusiso Sithole, City Manager - Invitation To...  Newspaper  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zu_en_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reverse-liver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zu</th>\n",
       "      <th>zu.1</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Peter Van Sant: And it means what?</td>\n",
       "      <td>Peter Van Sant: Bese kusho ukuthini?</td>\n",
       "      <td>U-Peter Van Sant: Pho kusho ukuthini lokho?</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The cost to society will be substantial, the r...</td>\n",
       "      <td>Izindleko zomphakathi zizoba zinkulu, ngokusho...</td>\n",
       "      <td>Lo mbiko uthi, izindleko ziyoba phezulu kakhul...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is now up to them to make the most of it.</td>\n",
       "      <td>Sekulele kubo ukuthi bayisebenzise ngendlela e...</td>\n",
       "      <td>Manje kukubo ukwenza okungcono ngalokhu.</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The CPS is carefully considering all the avai...</td>\n",
       "      <td>\"I-CPS icubungulisisa lonke ulwazi olukhona, o...</td>\n",
       "      <td>\"I-CPS icabangela ngokucophelela lonke ulwazi ...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TV audiences were left outraged after a teenag...</td>\n",
       "      <td>Izibukeli zaku-TV zishiywe zimangele emuva kok...</td>\n",
       "      <td>Ababukeli be-TV basale beqhuma ngentukuthelo n...</td>\n",
       "      <td>News Crawl 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                 Peter Van Sant: And it means what?   \n",
       "1  The cost to society will be substantial, the r...   \n",
       "2       It is now up to them to make the most of it.   \n",
       "3  \"The CPS is carefully considering all the avai...   \n",
       "4  TV audiences were left outraged after a teenag...   \n",
       "\n",
       "                                                  zu  \\\n",
       "0               Peter Van Sant: Bese kusho ukuthini?   \n",
       "1  Izindleko zomphakathi zizoba zinkulu, ngokusho...   \n",
       "2  Sekulele kubo ukuthi bayisebenzise ngendlela e...   \n",
       "3  \"I-CPS icubungulisisa lonke ulwazi olukhona, o...   \n",
       "4  Izibukeli zaku-TV zishiywe zimangele emuva kok...   \n",
       "\n",
       "                                                zu.1           Source  \n",
       "0        U-Peter Van Sant: Pho kusho ukuthini lokho?  News Crawl 2019  \n",
       "1  Lo mbiko uthi, izindleko ziyoba phezulu kakhul...  News Crawl 2019  \n",
       "2           Manje kukubo ukwenza okungcono ngalokhu.  News Crawl 2019  \n",
       "3  \"I-CPS icabangela ngokucophelela lonke ulwazi ...  News Crawl 2019  \n",
       "4  Ababukeli be-TV basale beqhuma ngentukuthelo n...  News Crawl 2019  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_zu_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "temporal-traveler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zu</th>\n",
       "      <th>en_1</th>\n",
       "      <th>en_2</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ikomidi elihlelela imidlalo ye-2013 Orange Afr...</td>\n",
       "      <td>The 2013 Orange Africa Cup of Nations games (k...</td>\n",
       "      <td>The 2013 Orange Africa Cup of Nations (known a...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Futhi ipolitiki akuwona umdlalo wabantu abanga...</td>\n",
       "      <td>And politics is not a game of   immature people.</td>\n",
       "      <td>And politics is not a game for  immature people.</td>\n",
       "      <td>Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ikhasi lethu lakwa e-Careers likubeka ngokucac...</td>\n",
       "      <td>Our e-Careers page makes it clear that if you ...</td>\n",
       "      <td>Our e-Careers page makes it clear that if you ...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uma ngibabuza bathi indlu yami inkulu ngakho k...</td>\n",
       "      <td>When I ask them they say my house is big so I ...</td>\n",
       "      <td>When I ask them they say my house is big so I ...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kulonyaka i Earth Hour ifaka ne I Will If You ...</td>\n",
       "      <td>This year Earth Hour also includes I Will If Y...</td>\n",
       "      <td>This year Earth Hour also includes I Will If Y...</td>\n",
       "      <td>Newspaper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  zu  \\\n",
       "0  Ikomidi elihlelela imidlalo ye-2013 Orange Afr...   \n",
       "1  Futhi ipolitiki akuwona umdlalo wabantu abanga...   \n",
       "2  Ikhasi lethu lakwa e-Careers likubeka ngokucac...   \n",
       "3  Uma ngibabuza bathi indlu yami inkulu ngakho k...   \n",
       "4  Kulonyaka i Earth Hour ifaka ne I Will If You ...   \n",
       "\n",
       "                                                en_1  \\\n",
       "0  The 2013 Orange Africa Cup of Nations games (k...   \n",
       "1   And politics is not a game of   immature people.   \n",
       "2  Our e-Careers page makes it clear that if you ...   \n",
       "3  When I ask them they say my house is big so I ...   \n",
       "4  This year Earth Hour also includes I Will If Y...   \n",
       "\n",
       "                                                en_2     source  \n",
       "0  The 2013 Orange Africa Cup of Nations (known a...  Newspaper  \n",
       "1   And politics is not a game for  immature people.      Novel  \n",
       "2  Our e-Careers page makes it clear that if you ...  Newspaper  \n",
       "3  When I ask them they say my house is big so I ...  Newspaper  \n",
       "4  This year Earth Hour also includes I Will If Y...  Newspaper  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zu_en_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "operational-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "En_Corpus = en_zu_train['en'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wooden-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "Zu_Corpus = en_zu_train['zu'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vanilla-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model,save_model\n",
    "from tensorflow.keras.layers import Input, LSTM, GRU, Dense, Embedding, Activation, dot, concatenate, Bidirectional, Attention\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.layers import TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.backend import expand_dims, sum\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tensorflow.keras import activations\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "elegant-removal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cultural-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # 32\n",
    "EPOCHS = 25 # 25\n",
    "LSTM_NODES = 128 #128\n",
    "NUM_SENTENCES = 4000 # 9000\n",
    "MAX_NUM_WORDS = 5000 # 10000\n",
    "EMBEDDING_SIZE = 50 # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "honest-recycling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Ama-albhamu akhe e-solo eminyaka yawo-60 angam...\n",
       "1       Ukusuka lapho kuzobe sekulandela ukuthi uma uf...\n",
       "2       Ngemuva kweminyaka engamashumi amathathu u-St....\n",
       "3       Wynford yw sylfaenydd Stafell Fyw yng Nghaerdy...\n",
       "4       Iqembu lika-Unai Emery lisanqobe imidlalo emib...\n",
       "                              ...                        \n",
       "4734    Isithombe sibonisa ingane encane encelayo nges...\n",
       "4735    Sola abakhiqizi, abaguqula njalo babeke endawe...\n",
       "4736                        (U-Javier Garcia/i-BPI/i-REX)\n",
       "4737    \"Ngimhlonipha kakhulu u- Laura, Wenza umsebenz...\n",
       "4738    Kodwa nanoma bekunezimo zokuvalwa ezibuxakalal...\n",
       "Name: zu, Length: 4739, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_zu_train['zu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impaired-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_zu_train['en'].to_csv('my_en_train.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_train['zu'].to_csv('my_zu_train.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_train[['en','zu']].to_csv('my_enzu_train.txt', sep='\\t', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "essential-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_zu_eval['en'].to_csv('my_en_eval.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_eval['zu'].to_csv('my_zu_eval.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_eval['zu.1'].to_csv('my_zu1_eval.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_eval[['en','zu']].to_csv('my_enzu_eval.txt', sep='\\t', index=False, header = False)\n",
    "en_zu_eval[['en','zu.1']].to_csv('my_enzu1_eval.txt', sep='\\t', index=False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abstract-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "En_Corpus = open('my_en_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in En_Corpus.readlines():\n",
    "    #print(line)\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        input_sentences.append(line.strip('\\n'))\n",
    "    cnt = cnt+1\n",
    "En_Corpus.close()\n",
    "\n",
    "Zu_Corpus = open('my_zu_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in Zu_Corpus.readlines():\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        output_sentences.append(line.strip('\\n') + ' <EOS>')\n",
    "        output_sentences_inputs.append('<SOS> '+line.strip('\\n') )\n",
    "    cnt = cnt +1\n",
    "Zu_Corpus.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "multiple-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input: 4000\n",
      "num samples output: 4000\n"
     ]
    }
   ],
   "source": [
    "print(\"num samples input:\", len(input_sentences))\n",
    "print(\"num samples output:\", len(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitted-barrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 22100\n",
      "Length of longest sentence in input: 86\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(filters='')\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
    "num_words_input = len(word2idx_inputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "substantial-manitoba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 37001\n",
      "Length of longest sentence in the output: 77\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "human-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_sentences\n",
    "target_text_input = output_sentences_inputs\n",
    "target_text_output = output_sentences\n",
    "\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_text)\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "         \n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(target_text_input)\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(target_text_output)\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "decoder_targets_one_hot = np.zeros((len(input_sentences),max_out_len,num_words_output),dtype=np.uint8) # 'float32'\n",
    "\n",
    "#print('decoder_targets_one_hot ',decoder_targets_one_hot.shape)\n",
    "\n",
    "\n",
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "directed-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "encoder_embedding = Embedding(num_words_input, LSTM_NODES)\n",
    "\n",
    "x = encoder_embedding(encoder_inputs_placeholder)\n",
    "encoder = LSTM(LSTM_NODES, return_sequences = True, return_state=True)\n",
    "\n",
    "encoder_outputs, h, c = encoder(x)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_states_h, decoder_states_c = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "decoder_states = [decoder_states_h,decoder_states_c]\n",
    "\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs_placeholder,\n",
    "  decoder_inputs_placeholder], decoder_outputs)\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "model.compile(\n",
    "    #optimizer='rmsprop',\n",
    "    optimizer = opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "foster-teens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 86)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 86, 128)      2828928     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 77, 128)      4736256     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 86, 128), (N 131584      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 77, 128), (N 131584      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 77, 37002)    4773258     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 12,601,610\n",
      "Trainable params: 12,601,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "double-workstation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "113/113 [==============================] - 168s 1s/step - loss: 3.4397 - accuracy: 0.7561 - val_loss: 2.2538 - val_accuracy: 0.7807\n",
      "Epoch 2/100\n",
      "113/113 [==============================] - 157s 1s/step - loss: 2.2828 - accuracy: 0.7736 - val_loss: 2.2691 - val_accuracy: 0.7860\n",
      "Epoch 3/100\n",
      "113/113 [==============================] - 162s 1s/step - loss: 2.2321 - accuracy: 0.7742 - val_loss: 2.2710 - val_accuracy: 0.7864\n",
      "Epoch 4/100\n",
      "113/113 [==============================] - 159s 1s/step - loss: 2.1901 - accuracy: 0.7744 - val_loss: 2.3028 - val_accuracy: 0.7863\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "r = model.fit([encoder_input_sequences, decoder_input_sequences],decoder_targets_one_hot,\n",
    "              epochs=50, #50\n",
    "              validation_split=0.1,\n",
    "              callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "built-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Seq2Seq Model (Without Attention) for Eng to Zulu Translation\n",
    "model.save('Seq2Seq.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-powell",
   "metadata": {},
   "source": [
    "### Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "decent-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Train Corpus length is  4746\n",
      "Zulu Train Corpus length is  5003\n",
      "English Eval Corpus length is  998\n",
      "Zulu Eval Corpus length is  1000\n"
     ]
    }
   ],
   "source": [
    "# creating Joint Corpus of train using my_en_train and my_zu_train txts\n",
    "\n",
    "Eng_train_corpus = open(\"my_en_train.txt\",\"r\", encoding='utf-8')\n",
    "Eng_train_corpus = Eng_train_corpus.read().splitlines()\n",
    "print('English Train Corpus length is ',len(Eng_train_corpus))\n",
    "\n",
    "zu_train_corpus = open(\"my_zu_train.txt\",\"r\", encoding='utf-8')\n",
    "zu_train_corpus = zu_train_corpus.read().splitlines()\n",
    "print('Zulu Train Corpus length is ',len(zu_train_corpus))\n",
    "\n",
    "# Creating Joint Corpus of Eval using my_en_eval and my_zu_eval txts\n",
    "Eng_eval_corpus = open(\"my_en_eval.txt\",\"r\", encoding='utf-8')\n",
    "Eng_eval_corpus = Eng_eval_corpus.read().splitlines()\n",
    "print('English Eval Corpus length is ',len(Eng_eval_corpus))\n",
    "\n",
    "zu_eval_corpus = open(\"my_zu_eval.txt\",\"r\", encoding='utf-8')\n",
    "zu_eval_corpus = zu_eval_corpus.read().splitlines()\n",
    "print('Zulu Eval Corpus length is ',len(zu_eval_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "neural-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming to make corpuses same length Zulu = Eng, \n",
    "zu_train_corpus = zu_train_corpus[0:4746]\n",
    "zu_eval_corpus = zu_eval_corpus[0:998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "coated-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint Corpus for train\n",
    "joint_Corpus_file = open('joint_train_Corpus.txt','w',encoding='utf-8')\n",
    "for i in range(len(Eng_train_corpus)):\n",
    "    joint_Corpus_file.write(Eng_train_corpus[i] + '|' +  zu_train_corpus[i] + '\\n')\n",
    "joint_Corpus_file.close()\n",
    "\n",
    "# Joint Corpus for Eval\n",
    "joint_Corpus_file = open('joint_eval_Corpus.txt','w',encoding='utf-8')\n",
    "for i in range(len(Eng_eval_corpus)):\n",
    "    joint_Corpus_file.write(Eng_eval_corpus[i] + '|' +  zu_eval_corpus[i] + '\\n')\n",
    "joint_Corpus_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "traditional-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Joint train and eval datasets.\n",
    "eng_zu_Corpus = open(\"joint_train_Corpus.txt\",\"r\", encoding='utf-8') # Train data\n",
    "eng_zu_Corpus = eng_zu_Corpus.read().splitlines()\n",
    "df = pd.DataFrame(eng_zu_Corpus)\n",
    "\n",
    "eng_zu_Corpus2 = open(\"joint_eval_Corpus.txt\",\"r\", encoding='utf-8') # Eval Data (zu not zu1)\n",
    "eng_zu_Corpus2 = eng_zu_Corpus2.read().splitlines()\n",
    "df2 = pd.DataFrame(eng_zu_Corpus2)\n",
    "# X_train, X_test = train_test_split(df[0:10000], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "christian-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_zu_train = np.array(df)\n",
    "eng_zu_test = np.array(df2)\n",
    "\n",
    "### create train file for English and Zulu by splitting the text by \"!\"\n",
    "eng_Corpus_train = open(\"eng_Corpus_train.txt\",\"w\", encoding='utf-8')\n",
    "zu_Corpus_train = open(\"zu_Corpus_train.txt\",\"w\", encoding='utf-8')\n",
    "\n",
    "for i in range(eng_zu_train.shape[0]):\n",
    "    eng_Corpus_train.write(eng_zu_train[i][0].split('|')[0] + '\\n')\n",
    "    zu_Corpus_train.write(eng_zu_train[i][0].split('|')[1] + '\\n')\n",
    "\n",
    "eng_Corpus_train.close()\n",
    "zu_Corpus_train.close() \n",
    "\n",
    "### create test file for English and Zulu by splitting the text by \"!\"\n",
    "\n",
    "eng_Corpus_test = open(\"eng_Corpus_test.txt\",\"w\", encoding='utf-8')\n",
    "zu_Corpus_test = open(\"zu_Corpus_test.txt\",\"w\", encoding='utf-8')\n",
    "\n",
    "for i in range(eng_zu_test.shape[0]):\n",
    "    eng_Corpus_test.write(eng_zu_test[i][0].split('|')[0] + '\\n')\n",
    "    zu_Corpus_test.write(eng_zu_test[i][0].split('|')[1] + '\\n')\n",
    "\n",
    "eng_Corpus_test.close()\n",
    "zu_Corpus_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "naughty-excess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input: 4000\n",
      "num samples output: 4000\n"
     ]
    }
   ],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "En_Corpus = open('eng_Corpus_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in En_Corpus.readlines():\n",
    "    #print(line)\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        input_sentences.append(line.strip('\\n'))\n",
    "    cnt = cnt+1\n",
    "En_Corpus.close()\n",
    "\n",
    "zu_Corpus = open('zu_Corpus_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in zu_Corpus.readlines():\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        output_sentences.append(line.strip('\\n') + ' <EOS>')\n",
    "        output_sentences_inputs.append('<SOS> '+line.strip('\\n') )\n",
    "        \n",
    "    cnt = cnt +1\n",
    "zu_Corpus.close()\n",
    "\n",
    "print(\"num samples input:\", len(input_sentences))\n",
    "print(\"num samples output:\", len(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hungarian-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 22100\n",
      "Length of longest sentence in input: 86\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(filters='')\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
    "num_words_input = len(word2idx_inputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spread-probe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 37001\n",
      "Length of longest sentence in the output: 77\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "failing-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_sentences\n",
    "target_text_input = output_sentences_inputs\n",
    "target_text_output = output_sentences\n",
    "\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_text)\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "         \n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(target_text_input)\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(target_text_output)\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "decoder_targets_one_hot = np.zeros((len(input_sentences),max_out_len,num_words_output),dtype=np.uint8) # 'float32'\n",
    "\n",
    "#print('decoder_targets_one_hot ',decoder_targets_one_hot.shape)\n",
    "\n",
    "\n",
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "synthetic-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 86)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 86, 128)      2828928     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 77, 128)      4736256     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 86, 128), (N 131584      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 77, 128), (N 131584      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 77, 37002)    4773258     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 12,601,610\n",
      "Trainable params: 12,601,610\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('Seq2Seq.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "arbitrary-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Inference Purpose\n",
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))#model.get_layer('input_1')\n",
    "encoder_embedding = model.get_layer('embedding')\n",
    "encoder_lstm = model.get_layer('lstm')\n",
    "\n",
    "x = encoder_embedding(encoder_inputs_placeholder)\n",
    "encoder_outputs, h, c = encoder_lstm(x)\n",
    "encoder_states = [h, c]\n",
    "\n",
    "#Define Encoder Model\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_states)  #without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "duplicate-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_outputs shape: (None, 1, 128)\n"
     ]
    }
   ],
   "source": [
    "decoder_state_input_h = Input(shape=(LSTM_NODES,),name='decoder_h_input')\n",
    "decoder_state_input_c = Input(shape=(LSTM_NODES,),name='decoder_c_input')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding = model.get_layer('embedding_1')\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,),name='decoder_single_input')\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "decoder_lstm = model.get_layer('lstm_1')\n",
    "\n",
    "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [h, c]\n",
    "print('decoder_outputs shape:',decoder_outputs.shape)\n",
    "\n",
    "decoder_dense = model.get_layer('dense')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "working-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "harmful-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_out_len):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "separate-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "\n",
    "input_sentences_test = []\n",
    "output_sentences_test = []\n",
    "\n",
    "En_Corpus_test = open('eng_Corpus_test.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in En_Corpus_test.readlines():\n",
    "    #print(line)\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        input_sentences_test.append(line.strip('\\n'))\n",
    "    cnt = cnt+1\n",
    "En_Corpus_test.close()\n",
    "\n",
    "zu_Corpus_test = open('zu_Corpus_test.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in zu_Corpus_test.readlines():\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        output_sentences_test.append(line.strip('\\n') + ' <EOS>')\n",
    "    cnt = cnt +1\n",
    "zu_Corpus_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "vietnamese-lesbian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "smooth = SmoothingFunction().method2 # math domain error with method4, trying method 2 or 1 or 0 (No Smoothing)\n",
    "\n",
    "def calculate_bleu(text1,text2):\n",
    "    hypothesis = text1.split()\n",
    "    reference = text2.split()\n",
    "\n",
    "    reference_list = [reference] # list of references for 1 sentence.\n",
    "    bleu_score = nltk.translate.bleu_score.sentence_bleu(reference_list, hypothesis,smoothing_function = smooth)\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "buried-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Corpus Bleu Score without attention: 0.001520824298441906\n"
     ]
    }
   ],
   "source": [
    "test_pred_result = open('test_prediction_without_attention','w',encoding = 'utf-8')\n",
    "test_sent_bleu = {}\n",
    "for s in range(len(input_sentences_test)):\n",
    "    input_integer_seq = input_tokenizer.texts_to_sequences([input_sentences_test[s]])\n",
    "    encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "    translation = translate_sentence(encoder_input_sequences)\n",
    "    sent_bleu = calculate_bleu(output_sentences_test[s].strip('<EOS>'),translation)\n",
    "    test_sent_bleu[s] = sent_bleu\n",
    "    text = str(s) + ' ' + input_sentences_test[s] + '|' + output_sentences_test[s].strip('<EOS>') + 'Predicted: ' + translation + ' Bleu Score: ' + str(sent_bleu)\n",
    "    test_pred_result.write(text + '\\n')\n",
    "test_pred_result.close()\n",
    "\n",
    "test_cospus_score = np.sum(list(test_sent_bleu.values()))/len(input_sentences_test)\n",
    "print('Test Corpus Bleu Score without attention:',test_cospus_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "median-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224 This looks fab and really sets off your festive decorations - but given that you have to pop each balloon to access each day's chocolate, it's probably one to avoid with very young children. Unless your little ones will be able to resist popping all the balloons at once. Ours weren't, and they're old enough to know better.|Kubukeka kukuhle lokhu futhi kuqalisa imihlobiso yangesikhathi sokuzijabulisa - kodwa njengoba kuzodingeka uqhumise ibhaluni ukuthola ushokoledi wosuku nosuku, mhlawumbe kungadingeka ukubalekele lokho uma unezingane ezincane. Ngaphandle kwalapho izingane zakho zizokwazi ukumela ukuqhuma kwawo wonke amabhaluni ngesikhathi esisodwa. Ezethu zazingeke zikwazi, futhi sezindala ngokwanele ukuthi zazi kangcono. Predicted: kodwa ukuthi uthe ukuthi uthe ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.015932835357335126\n",
      "959 Following their successful Cork appearances cooking, foraging and fishing, the four chefs moved on to Dublin, where they are due to prepare a bush tucker dinner for 176 people on Friday night, local time. From there the Bourke twins will do a placement in a three Michelin-starred restaurant in London.|\"Utshele abasohlweni lwaNamuhla lwe-BBC Radio 4: \"\"Ave nje kumayelana nemithethonqubo iNorthern Ireland ezophoqeleka ukuba ilandele i-backstop, kodwa kuphinde kube wukuba kuzodingeka ukuba i-United Kingdom iyonke njengezwe lesithathu, angeke sizibandakanye ezivumelwaneni sokuhweba i-United Kingdom engase ingene kuzo ngomuso futhi sithola ukuthi kuzoba nomngcele ezansi koLwandle lwama-Irish, okungavimba uhwebo lwethu nozakwethu abakhulu bezohwebo, okuyi-GB.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.015879914974453572\n",
      "12 \"\"\"We are excited that this tool has proven useful to guide local restoration efforts such as the Swan Island Oyster Sanctuary restoration project currently underway in North Carolina,\"\" Theuerkauf says. \"\"The beauty of this model and approach is that it can be modified for use in a number of different habitat restoration efforts -- such as mangrove restoration in Florida, where the benefits the habitat provides are different from those of oyster reefs, but similarly very valuable.\"\"\"|\"\"\"Siyakujabulela ukuthi le nsiza ibonakalile ukuthi izosiza ukuhola ukuvuselelwa kwe-Swan Island Oyster Sanctuary kwasendaweni oqhubekayo njengamanje eNorth Carolina,\"\" kusho uTheuerkauf.  \"\"Okuhle ngalolu hlelo nendlelakwenza wukuthi ingalungiselelwa ukusetshenziswa ezindaweni zokuhlala ezahlukene zokubuyisa -- njengokubuyiselwa kwezihlahla ze-mangrove eFlorida, lapho izinzuzo ezihlinzekwa yileyo ndawo zehlukile kunalezo zothunge lwembada, kodwa nazo zibaluleke ngokufanayo.\"\" \" Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.015574602165176733\n",
      "139 Shellfish collected by children are most easily identified by variety and size, Keegan said. Child foragers tend to be generalists, meaning that they're more likely to collect small shells indiscriminately. This research suggests that small, easy to transport and low-yield mollusks found in high amounts on a site indicate the presence of child foragers, he said.|Ama-shellfish aqoqwa izingane kuvame ukuba lula ukuwahlonza ngokohlobo nobungako, kusho uKeegan. Abadobi abayizingane bavame ukubheka okujwayelekile, okusho ukuthi maningi kakhulu amathuba okuthi baqoqe amagobolondo amancane ngaphandle kokukhetha. Uthe, lolu cwaningo lusho ukuthi izinkovu ezincane, okulula ukuzithutha nezinenzuzo encane ezitholakala ziziningi kakhulu endaweni ziveza ukuthi bekukhona abadobi abayizingane. Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.015032442612898437\n",
      "594 Sept des huit raffineries sont en grève, fait savoir Emmanuel Lépine, secrétaire fédéral CGT Chimie.|\"U-Dean wanezela: \"\"Kuthathe isikhathi esingaphezu kwengxenye yekhulu leminyaka ukuba lesi silwane, i-ichthyosaur sicwaningwe futhi sichazwe, kodwa siyabonga ukuthi salinda. Ucwaningo lwethu alugcinanga nje ngokuveza ulwazi olujabulisayo ngokwakheka kwangaphakathi kwekhanda lalesi silwane, kodwa esikutholile kuzosiza namanye ama- palaeontologist ekucingeni nasekufundeni ngobuhlobo obukhona bokuguquka kanye namanye ama- ichthyosaurs.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.01482717400280981\n",
      "876 The three-year-old firm said turnover had risen from just £94,000 in year one to £432,257 in year three, marking a 360 per cent increase.|NgoLwesihlanu ekuseni, uTrump umemezele ukuthi kuzobambezeleka izintela zezithuthi zakwamanye amazwe kanye nezingxenye zazo izinyanga eziyisithupha. Lokho kunika abaxoxisana nabahwebi izinsuku eziyi-180 zokubonisana ngesivumelwano sokuthenga neJaphani kanye ne-EU ngaphambi kokusebenzisa lezo zintela, ezizonyusa amanani ezimoto ezenziwe kwamanye amazwe kanye nezingxenye zazo e-United States. Omele abahwebi e-US uRobert Lighthizer uzohola izingxoxo futhi abikele uTrump, kusho umongemeli esimemezelweni sakhe. Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.014794965009173816\n",
      "140 Soyuncu still needs a little refinement, of course. The only game Leicester have lost this season was, ironically, to Manchester United, where Marcus Rashford lured Soyuncu into conceding a penalty. The evidence so far suggests that Rodgers and Evans will help the centre-back to become more accomplished without losing his personality. The Leicester coach Kolo Touré will surely also have good counsel to give on that front.|USoyuncu usadinga ukulungiswa kancane, nakanjani. Umdlalo owodwa i-Leicester eyahlulwe kuwo kuleli hlandla lokudlala kube, ngokuqondana, owe-Manchester United, lapho uMarcus Rashford aheha uSoyuncu ukuthi ayekele iphenalthi. Ubufakazi okwamanje busho ukuthi uRodgers no-Evans bazosiza umdlali wasesiswini odlala emuva aphumelele kangcono ngaphandle kokulahlekelwa ubuyena. Umqeqeshi we-Leicester uKolo Touré nakanjani uzoba nezeluleko ezilungile azomnika zona maqondana nalokho. Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.014473198949901626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897 They explain how the air we breathe oxygenates our lungs.|ndaweni yokudlela esikoleni ngesikhathi sokudla, lapho abangani bami babehleba begigitheka ngabafana, ngangifunda ikhasi namakhasi umama wami ayechaza kuwo ukuthi wazibamba kanjani, ngomzuzu wokugcina, ekuziphoseni eweni noma ekuziphoseni olwandle ukuze aminze. Wabhala ukuthi wayengithanda kangakanani futhi esikhumbula kakhulu kangakanani sonke. Kuze kuba manje, akakaze abuye. Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.0143765168439508\n",
      "966 It isn't clear if the water colour is due to the sewage works.|\"Ngokususela \"\"olwazini olukholakalayo,\"\" uCallamard ubone ukuthi bekunobufakazi obanele obuveza ukuthi iTurkey noma i-United States beyazi, noma bekumele ngabe beyazi, ngobungozi bangempela noma obebungase bube khona empilweni kaKhashoggi. Kube nokuhlawumbisela ngokuthi kungenzeka na ukuthi i-CIA beyazi ngobungozi obubhekiswe kuKhashoggi bese bangamuqwashisa, njengoba bekulindelekile ngokomthetho.\" Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.01413000001328818\n",
      "934 Joe Root (c) - Yorkshire|\"\"\"Kuyangijabulisa ukuzwa umbono wabo,\"\" kuphendula uJoshua, ngaphambi kokugcizelela ukuthi akasilo iqhawe elingaqeda izinkinga zomhlaba ngomlingo. Uma ebhekene nencindezi, uyangunuza esho into ethile \"\"ngokuvuselela\"\" bese aphakamise ukuthi angasebenzisa ubudlelwano bakhe ne-Saudis ukubuza imibuzo enzima kunokuba \"\"asole, akhombe ngeminwe futhi amemeze eseGreat Britain.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.01359175368635888\n",
      "819 We've got almost 700 workers in Scotland and where do they go?'|Lokho kuhambisana nabantu besifazane abashiya izigidi ematafuleni ngoba isikhathi sabo futhi kudingeka abasebenzi ukuze kukhuliswe isizukulwane esilandelayo. Kuhambisana nabantu abampisholo ukusebenza kanzima kunozakwabo abamhlophe kodwa abakwazi ukugaqa baphume esikweletini futhi bazakhele owabo umcebo ngaphandle kwengcebo yezizukulwane eyebiwa kukhuluminyaka obugqila nokucwasa. Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.013298904622536072\n",
      "825 If it wasn't for this food bank these two would be eating pretty much nothing.|\"UKaregeya, osebenza nezobunhloli zase-Uganda, waqala wasala ekubonisaneni, unomsebenzi wokuxhumanisa okhomanda emkhakheni neMuseveni, kodwa ubuyele eKigali ekupheleni konyaka we-1994 ukuze angenele ezobunhloli bamazwe ngamazwe. UKayumba ungitshele ukuthi \"\"uPatrick usethole abantu abaningi angaxhumana nabo kwezobunhloli.\"\" \"\"Wayenolwazi oluningi, sonke sasicabanga ukuthi uhlakaniphe kakhulu.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.013298904622536072\n",
      "401 \"\"\"We were really good that tournament right the way through to the final. I don't think it motivates or carries me to do any better,\"\" Genia said. \"\"It's just embracing it and enjoying it. It's once every four years. It's a different kind of buzz and a different kind of energy when you are here when you are playing at a World Cup because all the attention is on rugby.\"\"\"|\"\"\"Sidlale kahle kakhulu kulowo mqhudelwano zibekwa nje kwaze kwafikwa ekugcineni. Angiboni ukuthi kuyakhuthaza noma kungiqhuba kangcono,\"\" kusho uGenia. \"\"Wukukwamukela nje nokukujabulela. Kuba njalo eminyakeni emine. Wuhlobo oluhlukile lomsindo futhi uhlobo oluhlukile lwamandla uma ulapha uma udlala kwiNdebe Yomhlaba ngoba kunakwa kakhulu umdlalo webhola lombhoxo.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012990649425124628\n",
      "47 \"In a statement to CNBC, United Technologies said, \"\"We are confident that our shareholders will see the merits of this transaction and the value it brings to them and the company. We will be working diligently in the days and weeks ahead to make sure that the details of the transaction are presented to and fully understood by all shareholders.\"\"\"|\"Esitatimendeni ebesibhekiswe kwi-CNBC, i-United Technologies ithe, \"\"Siyethemba ukuthi abaninizabelo bethu bazokubona okuvuna leli phuzu kanye nenzuzo etholwa yibo kanye nenkampani ngayo. Sizobe sisebenza ngokuzimisela ngezinsuku nangamaviki ezayo ukuqinisekisa ukuthi imininingwane yokuvunyelwana ngakho iyathulwa futhi iqondwe ngokugcwele yibo bonke abaninizabelo.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012989515546337095\n",
      "321 For a majority of people, music is a part of everyday life, and living without it is impossible. It's a constant companion, one that kids develop a taste for during their formative years and bring with them as an adult. Some merely use it as a distraction, while some love it so much that it influences them as a person. Some even write it for a living.|bantwini abaningi, umculo uyingxenye yempilo yansukuzonke, futhi ayikho indlela yokuphila ngaphandle kwawo. Kuhlala kuhamba phambili, uyilokho izingane eziqala ukukuthanda zisezincane futhi ziqhubeke nakho nasebudaleni. Abanye bawusebenzisa njengento yokuphazamisa, kube abanye bawuthanda kangangoba uba nomthelela kubo njengabantu. Abanye baze bawubhale okuba yindlela yabo yokuziphilisa. Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012767896323014338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348 Unlike cryptocurrencies such as bitcoin, nifties are cryptographic tokens that represent a unique asset or good on the blockchain, are one of a kind, and are not interchangeable. Blockchains can enable gamers to buy and trade interoperable digital collectibles such as skins, dances, and in-game items, helping further fuel a $50 billion-plus annual market1 for virtual goods.|Hhayi njengama-cryptocurrencies anjenge-bitcoin, ama-nifties angamathokheni anezithombe ezi-cryptographic ezimele impahla ehlukile kwi-blockchain, okungavamile, futhi okungasebenziseki ngokushintshanisa. Ama-blockchain angenza abadlali bathenge futhi bahwebe ngezinto ezisebenza ngobuchwepheshe bedijithali ezoqoqekayo njengama-skin, abadansi, nezinto zemidlalo, okusiza ukuqhubeka nokufaka isamba esingaphezu kwezigidigidi ezingu-$50 ezimakethe maqondana nempahla yezobuchwepheshe ephakathi kumakhompyutha. Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012767896323014338\n",
      "674 \"\"\"Ball first,\"\" \"\"footwork\"\" and \"\"accuracy\"\" were common refrains. They won't outslug anyone, Lung said, so the players must master the little things.\"|Njengaba uMnu. Biden elindeleke ukuthi amemezele ukuthi ingabe uzongenela umncintiswano wobumongameli ngo-Ephreli, indaba kaNksz. Flore yadala ukuthi kucutshungulwe ukusebenzisana kwakhe nabantu besimame esikhathini sakhe eside esebenza kwezepolitiki likazwelonke. NgeSonto, uMnu. Biden ukhiphe isitatimende ezivikela, ethi bengakholwa wukuthi kukhona okungafanele ake akwenza emkhankasweni wakhe. Predicted: kodwa ukuthi uthe ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012767896323014338\n",
      "745 \"\"\"I'm very grateful for the personal support I have been getting,\"\" and argues the constitutional question is not uppermost in voters mind.\"|\"\"\"Ngenza into engavamile ethuse abagibeli abebengalindele ― Ngifake imaskhi yephepha njalo emuva kwamahora ambalwa! Ngithenga amaphakethe amamaskhi ephepha ase-Asia aqeda ukoma kwesikhumba, angenawo amakha ukuze angasiphazamisi isikhumba sami noma amakhala abantu abasondelene nami. Bavame ukuqukatha i-hyaluronic acid kanye nezinye izithako ezilungele ukugcoba isikhumba ... Lokhu kugcina isikhumba sami singomanga futhi singangibangeli inkinga ohambweni lwebhanoyi lonke.\"\" ― La Carmina\" Predicted: kodwa ukuthi ukuthi ukuthi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012589294716796897\n",
      "39 Last week, the South Bend City Councilman Oliver Davis endorsed former Vice President Joe Biden in what several outlets viewed as a rejection of Mayor Pete. On Friday, Davis told Politico that he's happy to see someone representing Indiana on the national stage, but Biden offered more experience than the 37-year-old.|Ngeviki eledlule, u-Oliver David Ongumuntu Wasemkhandlwini weDolobha i-South Bend wesekele uSekela Mongameli uJoe Biden kulokho izikhungo eziningi ezikubone kuwukuchitha uSodolobha uPete. NgoLwesihlanu, uDavis utshele i-Politico ukuthi ukujabulele ukubona umuntu omele i-Indiana kuzwelonke, kodwa uBiden ubonakalise ukuba nesipiliyoni esiningi kunalo muntu oneminyaka engama-37. Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012531695204821355\n",
      "402 \"Anirban Lahiri of India did not have to qualify for his previous two U.S. Opens, and he doesn't want to have to go through it again. Lahiri had no trouble with a 65 at Scioto and a 67 at Brookside, but he could do without the stress. He had never seen either course, opting for what he called \"\"point and shoot.\"\"\"|\"U-Anirban Lahiri waseNdiya akazange afaneleke ukungena kuma-U.S. Open amabili adlule, futhi akudingeki aphinde adlule kuwo futhi. ULahiri akabanga nenkinga ne-65 at Scioto kanye ne-67 at Brookside, kodwa ubengakwenza ngaphandle kwengcindezi. Ubengakazi azibone zonke izinkundla zokudlala, wakhetha lokhu akubize ngokuthi \"\"point and shoot.\"\"\" Predicted: kodwa ukuthi ukuthi ukuthi uthe futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi futhi Bleu Score: 0.012531695204821355\n"
     ]
    }
   ],
   "source": [
    "test_sent_bleu_sorted_index = sorted(test_sent_bleu, key=test_sent_bleu.get, reverse=True)\n",
    "\n",
    "test_best = []\n",
    "for i in test_sent_bleu_sorted_index[0:20]:\n",
    "    test_best.append(i)\n",
    "\n",
    "for s in test_best:\n",
    "    input_integer_seq = input_tokenizer.texts_to_sequences([input_sentences_test[s]])\n",
    "    encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "    translation = translate_sentence(encoder_input_sequences)\n",
    "    sent_bleu = calculate_bleu(output_sentences_test[s].strip('<EOS>'),translation)\n",
    "    test_sent_bleu[s] = sent_bleu\n",
    "    text = str(s) + ' ' + input_sentences_test[s] + '|' + output_sentences_test[s].strip('<EOS>') + 'Predicted: ' + translation + ' Bleu Score: ' + str(sent_bleu)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-practice",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-matrix",
   "metadata": {},
   "source": [
    "## With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "interstate-integer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples input: 4000\n",
      "num samples output: 4000\n"
     ]
    }
   ],
   "source": [
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "\n",
    "En_Corpus = open('eng_Corpus_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in En_Corpus.readlines():\n",
    "    #print(line)\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        input_sentences.append(line.strip('\\n'))\n",
    "    cnt = cnt+1\n",
    "En_Corpus.close()\n",
    "\n",
    "zu_Corpus = open('zu_Corpus_train.txt','r',encoding = 'utf-8')\n",
    "cnt = 0 \n",
    "for line in zu_Corpus.readlines():\n",
    "    if cnt < NUM_SENTENCES:\n",
    "        output_sentences.append(line.strip('\\n') + ' <EOS>')\n",
    "        output_sentences_inputs.append('<SOS> '+line.strip('\\n') )\n",
    "        \n",
    "    cnt = cnt +1\n",
    "zu_Corpus.close()\n",
    "\n",
    "print(\"num samples input:\", len(input_sentences))\n",
    "print(\"num samples output:\", len(output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "governmental-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 22100\n",
      "Length of longest sentence in input: 86\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(filters='')\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
    "num_words_input = len(word2idx_inputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "junior-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 37001\n",
      "Length of longest sentence in the output: 77\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
    "\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sexual-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = input_sentences\n",
    "target_text_input = output_sentences_inputs\n",
    "target_text_output = output_sentences\n",
    "\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_text)\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "         \n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(target_text_input)\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(target_text_output)\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "          \n",
    "decoder_targets_one_hot = np.zeros((len(input_sentences),max_out_len,num_words_output),dtype=np.uint8) # 'float32'\n",
    "\n",
    "#print('decoder_targets_one_hot ',decoder_targets_one_hot.shape)\n",
    "\n",
    "\n",
    "for i, d in enumerate(decoder_output_sequences):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "casual-engineering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n",
      "encoder_outputs shape: (None, 86, 256)\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
    "encoder_embedding = Embedding(num_words_input, LSTM_NODES)\n",
    "\n",
    "x = encoder_embedding(encoder_inputs_placeholder)\n",
    "encoder_biLSTM = Bidirectional(LSTM(LSTM_NODES, return_sequences = True, return_state=True),merge_mode= 'concat')\n",
    "\n",
    "encoder_outputs, h_forward, c_forward,h_backward,c_backward = encoder_biLSTM(x)\n",
    "\n",
    "encoder_h = concatenate([h_forward,h_backward],axis = 1)\n",
    "encoder_c = concatenate([c_forward,c_backward],axis = 1)\n",
    "print(encoder_h.shape)\n",
    "encoder_states = [encoder_h, encoder_c]\n",
    "print('encoder_outputs shape:',encoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "occasional-indian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder outputs shape: (None, 77, 256)\n",
      "decoder_states_h shape: (None, 256)\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
    "\n",
    "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "decoder_lstm = LSTM(LSTM_NODES*2, return_sequences=True, return_state=True)\n",
    "\n",
    "decoder_outputs, decoder_states_h, decoder_states_c = decoder_lstm(decoder_inputs_x,initial_state=encoder_states)\n",
    "\n",
    "decoder_states = [decoder_states_h,decoder_states_c]\n",
    "print('decoder outputs shape:',decoder_outputs.shape)\n",
    "print('decoder_states_h shape:',decoder_states_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "senior-fault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bahdanau attention\n",
    "from tensorflow.keras import activations\n",
    "w1 = Dense(10)\n",
    "w2 = Dense(10)\n",
    "v =  Dense(1)\n",
    "\n",
    "#decoder_h_timeaxis = expand_dims(decoder_states_h,1)\n",
    "encoder_h_timeaxis = expand_dims(encoder_h,1)\n",
    "\n",
    "score = v(activations.tanh(w1(encoder_h_timeaxis) + (w2(encoder_outputs)) ))\n",
    "attention_softmax = activations.softmax(score,axis=1)\n",
    "context = attention_softmax * encoder_outputs\n",
    "context_vector = sum(context,axis=1)\n",
    "context_vector_timeaxis = expand_dims(context_vector,1)\n",
    "decoder_combined_context = context_vector_timeaxis + decoder_outputs\n",
    "\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_combined_context)\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs_placeholder,\n",
    "  decoder_inputs_placeholder], decoder_outputs)\n",
    "\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "model.compile(\n",
    "    optimizer = opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "disciplinary-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 86)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 86, 128)      2828928     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 86, 256), (N 263168      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_2 (TFOpLambda)   (None, 1, 256)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1, 10)        2570        tf.expand_dims_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 86, 10)       2570        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 86, 10)       0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.tanh_1 (TFOpLambda)     (None, 86, 10)       0           tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 86, 1)        11          tf.math.tanh_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.softmax_1 (TFOp (None, 86, 1)        0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 86, 256)      0           tf.compat.v1.nn.softmax_1[0][0]  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 77)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 256)          0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 77, 128)      4736256     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_3 (TFOpLambda)   (None, 1, 256)       0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 77, 256), (N 394240      embedding_5[0][0]                \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 77, 256)      0           tf.expand_dims_3[0][0]           \n",
      "                                                                 lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 77, 37002)    9509514     tf.__operators__.add_3[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 17,737,257\n",
      "Trainable params: 17,737,257\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "atmospheric-flashing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "113/113 [==============================] - 225s 2s/step - loss: 2.8165 - accuracy: 0.7580 - val_loss: 2.2645 - val_accuracy: 0.7859\n",
      "Epoch 2/25\n",
      "113/113 [==============================] - 219s 2s/step - loss: 2.2754 - accuracy: 0.7740 - val_loss: 2.2603 - val_accuracy: 0.7861\n",
      "Epoch 3/25\n",
      "113/113 [==============================] - 214s 2s/step - loss: 2.2114 - accuracy: 0.7744 - val_loss: 2.2755 - val_accuracy: 0.7865\n",
      "Epoch 4/25\n",
      "113/113 [==============================] - 207s 2s/step - loss: 2.1681 - accuracy: 0.7746 - val_loss: 2.2667 - val_accuracy: 0.7862\n",
      "Epoch 5/25\n",
      "113/113 [==============================] - 248s 2s/step - loss: 2.1323 - accuracy: 0.7748 - val_loss: 2.2862 - val_accuracy: 0.7861\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "r = model.fit([encoder_input_sequences, decoder_input_sequences],decoder_targets_one_hot,\n",
    "              epochs=25,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "comic-education",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = r.history['loss']\n",
    "val_loss   = r.history['val_loss']\n",
    "xc         = range(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "white-inspection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b58db9a280>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Attention Model - Loss vs Epoch')\n",
    "plt.plot(train_loss,label= 'Train Loss')\n",
    "plt.plot(val_loss, label = 'Validation Loss')\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "confused-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Seq2Seq_attention.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-kazakhstan",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
